"""
Import data into the records database from a Records Transfer Box Inventory Excel document, an SF-135, or both.
The SF-135 must be generated by ARCIS from an existing records transfer request. The Box Inventory must be created
using the records_box_inventory_dena_template.xlsx file found at https://github.com/smHooper/recordsdb. If only an
SF-135 is given, the TRANSFER NUMBER on the PDF must already exist in the records database.

Usage:
    import_transferred_records.py --box_inventory_path=<str>
    import_transferred_records.py --sf135_path=<str>
    import_transferred_records.py --box_inventory_path=<str> --sf135_path=<str>

Options:
    -h, --help                      Show this screen.
    -i, --box_inventory_path=<str>  Path to a Records Transfer Box Inventory Excel file
    -s, --sf135_path=<str>          Path to an SF-135 PDF file
"""


import os
import re
import typing
import fitz
import openpyxl
import pandas as pd
from datetime import datetime
import sqlalchemy as sqla

import recordsdb_helper
from recordsdb.database import engine, models, SessionMaker
import recordsdb



SEARCH_FIELDS = {
    'b': 'arcis_transfer_number',
    'd': 'volume_cu_ft',
    'e': 'container_count',
    'f': 'series_description',
    'g': 'restriction',
    'h': 'disposition_authority',
    'i': 'disposition_date'
}

PDF_FIELD_MAP = {
    'Inclusive Start Date': 'start_date',
    'Inclusive End Date': 'end_date',
    'Security Classification': 'security_classification',
    'Security Level': 'security_level',
    'Disposition Code': 'disposition_code',
    'Disposition Citation': 'disposition_citation'
}

EXCEL_COLUMN_MAP = {
    'Box #': 'box_number',
    'Folder #': 'folder_number',
    'File Title': 'file_title',
    'Start Date (mm/yyyy)': 'start_date',
    'End Date (mm/yyyy)': 'end_date',
    'Cut-off Date': 'cutoff_date',
    'Additional File Description': 'description'
}

COLLECTION_FIELD_MAP = {
    'C4': 'collection_name',
    'C5': 'nps_file_code',
    'A9': 'description',
    'H3': 'transfer_location_code',
    'H4': 'prepared_by',
    'H5': 'prepared_date',
    'H6': 'arcis_transfer_number',
    'H7': 'park_division_code',
    'J7': 'program_area_code',
    'G9': 'tags',
}


def find_cell_x_bounds(cell_bounds: pd.DataFrame, search_rect: fitz.Rect) -> tuple:
    """
    Helper function to select the closest horizontal set of coordinates from cell_bounds to that of search_rect. This
    will be the cell that's just outside of search_rect or whose boundaries are the same as search_rect. This is only
    necessary because the transfer number cell is formatted like:
    _______________________
    |   TRANSFER NUMBER   |
    |_____________________|
    | (a) |  (b)  |  (c)  |
    |_____|_______|_______|
    | 079 | 2022  | 0049  |
    |     |       |       |
    |_____|_______|_______|

    To extract the field name and the value, this function receives the search_rect around '(b)' and finds the bounds
    around 'TRANSFER NUMBER'. For all other cells of field/value pairs, it just returns the search_rect of the cell

    :param cell_bounds: Pandas DataFrame of cell coordinates to select from
    :param search_rect: The rectangle to search around
    :return: tuple of horizontal bounds of matching cell
    """
    x0_diff = search_rect.x0 - cell_bounds.x1
    x0_diff = x0_diff.loc[x0_diff >= 0]
    left_cell_bound = cell_bounds.loc[x0_diff.idxmin(), 'x1']
    x1_diff = cell_bounds.x0 - search_rect.x1
    x1_diff = x1_diff.loc[x1_diff >= 0]
    right_cell_bound = cell_bounds.loc[x1_diff.idxmin(), 'x0']

    return left_cell_bound, right_cell_bound


def find_overlapping_words(extracted_word_info: list, search_rect: fitz.Rect) -> pd.DataFrame:
    """
    Helper function to get find words that intersect with search_rect

    :param extracted_word_info: single result of pdf.get_words()
    :param search_rect: the rectangle to search within
    :return: Pandas.DataFrame of words that intersect the rectangle
    """
    return pd.DataFrame(
        [w for w in extracted_word_info if fitz.Rect(*w[:4]).intersects(search_rect)],
        columns = ['x0', 'y0', 'x1', 'y1', 'text_str', 'block_no', 'line_no', 'word_no']
    )


def get_field_value(page: fitz.Page, letter: str, y_min: int, y_max: int, cell_bounds: pd.DataFrame, extracted_word_info: list=None) -> str:
    """

    :param page: PyMuPDF Page object
    :param letter: alphabet letter that corresponds to the field of interest in the SF-135
    :param y_min: The upper bound of the table
    :param y_max: The lower bound of the table
    :param cell_bounds: Pandas DataFrame of x/y bounds of vertical lines that define the bounds of the table cells
    :param extracted_word_info: result of pymupdf.Page.extract_text('words')
    :return:

    Each field is in the following format:
    ____________________________________
    |            FIELD NAME            |
    |             (LETTER)             |
    |__________________________________|
    |                                  |
    |              VALUE               |
    |                                  |
    |__________________________________|

    So get the value with the following steps:
        1. find the bounding box of the letter
        2. find the bounding box of the text above it (the field name)
        3. find the cell bounds on either side of the field name
        4. return any text that overlaps the maximum horizontal width of the cell but is BELOW the letter
    """


    if not extracted_word_info:
        extracted_word_info = page.get_text('words')

    letter_x0, letter_y0, letter_x1, letter_y1 = page.search_for(f'({letter})')[0]
    field_name_search_rect = fitz.Rect(letter_x0, y_min, letter_x1, letter_y0)

    # Can't just find the cell bounds directly on either side because the TRANSFER NUMBER field has sub-fields that
    #   would screw things up
    field_name_matches = find_overlapping_words(extracted_word_info, field_name_search_rect)
    cell_search_rect = fitz.Rect(field_name_matches.x0.min(), letter_y1, field_name_matches.x1.max(), y_max)

    left_cell_bound, right_cell_bound = find_cell_x_bounds(cell_bounds, cell_search_rect)
    value_search_rect = fitz.Rect(left_cell_bound, letter_y1, right_cell_bound, y_max)

    values = find_overlapping_words(extracted_word_info, value_search_rect)\
        .groupby('block_no').agg({'text_str': ' '.join})\
        .squeeze(axis=1)

    return values


def read_sf135(path: str) -> dict:
    """
    Extract data from an SF-135 (Records Transmittal Receipt) PDF returned from ARCIS after submitting a transfer request
    :param path: Path to the SF-135 PDF
    :return: dictionary of field_name, field_value
    """

    pdf = fitz.open(path)
    page = pdf[0]
    _, _, page_width, page_height = page.rect
    _, footer_y0, _, _ = page.search_for('Standard Form 135 (Rev.')[0]
    _, _, _, y_min = page.search_for('RECORDS DATA')[0]
    y_max = min(page_height, footer_y0) # only search down to the footer
    word_info = page.get_text('words')

    # Find the lines that define the vertical bounds of the table cells
    drawings = pd.DataFrame(page.get_drawings())
    horizontal_lines = drawings.loc[
        drawings.apply(lambda row: (row.rect.y1 - row.rect.y0 < 2) & (row.type == 'f'), axis=1)].rect
    top_table_line = horizontal_lines.loc[pd.Series({i: r.y0 - y_min for i, r in horizontal_lines.items()}).abs().idxmin()]
    y_min = top_table_line.y1
    table_rect = fitz.Rect(0, y_min, page_width, footer_y0)

    vertical_lines = drawings.loc[
        drawings.apply(
            lambda row:
                (row.rect.x1 - row.rect.x0 < 2) &
                (row.rect.intersects(top_table_line)) &
                (row.type == 'f'),
            axis=1)
    ].rect # type == 'f' is a "fill" object (i.e., a very thin, filled rectangle)
    cell_bounds = pd.DataFrame([{'x0': rect.x0, 'y0': rect.y0, 'x1': rect.x1, 'y1': rect.y1} for rect in vertical_lines])

    field_values = {}
    for field_letter, field_name in SEARCH_FIELDS.items():
        values = get_field_value(page, field_letter, y_min, y_max, cell_bounds, word_info)

        # Some fields annoyingly have multiple fields stored together (e.g., SERIES DESCRIPTION includes start and end
        #   dates). The field names end in a colon and the values are the next item
        if len(values) > 1:

            contained_field_names = values.loc[values.str.endswith(':')].str.strip(':').replace(PDF_FIELD_MAP)
            contained_field_values = values.loc[contained_field_names.index + 1]

            values.drop(contained_field_names.index.to_list() + contained_field_values.index.to_list(), inplace=True)
            field_values |= dict(
                    list(zip(contained_field_names, contained_field_values)) +
                    [[field_name, values.squeeze()]]
                )
        else:
            field_values |= {field_name: values.squeeze()}


    field_values['arcis_transfer_number'] = field_values['arcis_transfer_number'].replace(' ', '-')

    return field_values


def read_box_inventory(excel_path: str, conn: sqla.engine.Connection) -> typing.Tuple[dict, pd.DataFrame]:
    """
    Extract data from a Box Inventory Excel file
    :param excel_path:
    :return: dictionary of field/value pairs for single row of collections table, Pandas Dataframe for multiple Records table
    """
    # Get inventory table
    workbook = openpyxl.load_workbook(excel_path)
    sheet = workbook[workbook.sheetnames[0]]
    table = sheet.tables['box_inventory_data']

    # Get data from table as a DataFrame
    # Data extends beyond table bounds by one column
    x1, y1, x2, y2 = openpyxl.utils.range_boundaries(table.ref)
    data_range = f'{openpyxl.utils.get_column_letter(x1)}{y1}:{openpyxl.utils.get_column_letter(x2 + 1)}{y2}'
    table_contents = [[cell.value for cell in row] for row in sheet[data_range]]
    data = pd.DataFrame(table_contents[1:], columns=table_contents[0])\
        .dropna(how='all')\
        .rename(columns=EXCEL_COLUMN_MAP)

    collection_fields = {field_name: sheet[cell_address].value for cell_address, field_name in COLLECTION_FIELD_MAP.items()}

    # Replace names with codes for fields that reference lookup tables
    for field_name in collection_fields:
        if field_name.endswith('code'):
            field_value = collection_fields[field_name]
            lookup_values = pd.read_sql(f'''SELECT name, code FROM {field_name}s''', conn)\
                .set_index('name')\
                .squeeze(axis=1)
            if field_value in lookup_values.index:
                collection_fields[field_name] = lookup_values[field_value]

    nps_item = re.findall(r'^NPS Item [\d.a-zA-Z]+', collection_fields['nps_file_code'])[0].replace('NPS Item ', '')
    file_codes = pd.read_sql('SELECT nps_item, code FROM nps_file_codes', conn) \
        .set_index('nps_item') \
        .squeeze(axis=1)

    if nps_item in file_codes:
        collection_fields['nps_file_code'] = file_codes[nps_item]
    else:
        raise ValueError(f'NPS Item {nps_item} not in file codes')

    # attachment directory is stored in the config as a path relative to the package level directory
    attachments_dir = os.path.join(os.path.dirname(os.path.abspath(recordsdb.__file__)), recordsdb.config['attachments_dir'])
    file_name = os.path.basename(excel_path)
    collection_fields['box_inventory_path'] = os.path.join(attachments_dir, file_name)

    return collection_fields, data


def validate_transfer_number(transfer_number: str) -> typing.Optional[sqla.engine.ScalarResult]:
    """
    Helper method to ensure the transfer_number doesn't already exist in the database. If it does, that means the data
    were already imported
    :param transfer_number:
    :return: None
    """
    with SessionMaker.begin() as conn:
        statement = sqla.select(models.Collection).where(models.Collection.arcis_transfer_number == transfer_number)
        return conn.scalar(statement)


def main(box_inventory_path: str='', sf135_path: str=''):

    with SessionMaker.begin() as conn:
        inventory_data = {}
        if box_inventory_path:
            inventory_data, records_data = read_box_inventory(box_inventory_path, conn)

    sf135_data = {}
    if sf135_path:
         sf135_data = read_sf135(sf135_path)

    # If a box inventory was given, make sure the transfer number doesn't exist yet in the database because
    if inventory_data:
        # make sure the transfer number doesn't already exist in the database
        transfer_number = inventory_data['arcis_transfer_number']
        if transfer_number and validate_transfer_number(transfer_number):
            raise RuntimeError(
                f'The transfer number "{transfer_number}" already exists in the database. You can\'t import a Box'
                f' Inventory for a record series that was already imported.'
            )
    # If only the SF-135 was given, the collection has to already be in the database, so verify that it does
    elif sf135_data:
        transfer_number = sf135_data['arcis_transfer_number']
        if not validate_transfer_number(transfer_number):
            raise RuntimeError(
                f'The transfer number "{transfer_number}" does not exist in the database. You can only add data from an'
                f' SF-135 if the record series is already in the database or you also import a Box Inventory at the'
                f' same time'
            )

    if inventory_data and sf135_data:
        # Make sure the transfer numbers are the same
        inventory_transfer_number = inventory_data['arcis_transfer_number']
        sf135_transfer_number = sf135_data['arcis_transfer_number']
        if inventory_transfer_number != sf135_transfer_number:
            raise RuntimeError(
                f'The ARCIS transfer number given in the Box Inventory "{inventory_transfer_number}"'
                f' does not match the transfer number from the SF-135 "{sf135_transfer_number}"'
            )

    # Combine the data
    inventory_data |= sf135_data

    # Convert any date fields to ISO format
    for key, value in inventory_data.items():
        if key.endswith('_date'):
            try:
                inventory_data[key] = datetime.strptime(value, '%m/%d/%Y').strftime('%Y-%m-%d')
            except:
                raise ValueError(f'Date format of field {key} not understood: {value}')

    with SessionMaker.begin() as session:
        if box_inventory_path:
            #insert inventory_data to collections
            new_collection = models.Collection(**inventory_data)
            session.flush() # should add id to new_collection
            # insert boxes returning id
            # insert folders returning id
            #records_data.to_sql('records', session, index=False, if_exists='append')

if __name__ == '__main__':
    args = recordsdb.get_docopt_args(__doc__)
    main(**args)


    
    